{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Assignment_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOUzHRHN3vAT"
      },
      "source": [
        "# Binary Digit Classifier\n",
        "\n",
        "We have been offered a job at ML Solutions Limited to create a neural network classifier that can classify images of written binary digits (1 or 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulj2I5lI9guE"
      },
      "source": [
        "!pip install tensorflow keras numpy mnist matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKNbSN55uoc",
        "outputId": "6e30f85d-9a9b-415f-8803-b9b0a46ba288"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSbYnuQlQXat"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "import pandas as pd # data processing\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bqNYCG9tOn8"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkL32QxRtex6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7f7ac2-a31f-4f78-98be-7c1c2c2dea30"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2AJdfaZtj9r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c5d12cff-df63-4ef4-a27d-699fa64df072"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0], cmap= plt.cm.binary)\n",
        "plt.show()\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRwpCiLHtr7B"
      },
      "source": [
        "Now we want to take out the 1's and 0's from this dataset so that we can do classification on those. Here we are extracting the input data and their respective labels for those whose labeles have either 0 or 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8djEJFOtn5F"
      },
      "source": [
        "x_train, y_train = x_train[(y_train==1) | (y_train==0)],y_train[(y_train==1) | (y_train==0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7aMLCLCuGyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04887e1-55c8-4603-c0b0-ad78aa1d84eb"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 28, 28), (12665,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq5GcxhRvIZt"
      },
      "source": [
        "We do the same on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxITpob3u0il"
      },
      "source": [
        "x_test,y_test = x_test[(y_test==1) | (y_test==0)], y_test[(y_test==1) | (y_test==0)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBW7ikV84qKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3439cbb-3cb2-4471-fce9-2d378b6f5c79"
      },
      "source": [
        "x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2115, 28, 28), (2115,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJzC3f0Z6quy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_4SxcsLva_K"
      },
      "source": [
        "Let us see what our data looks like. We will pick a random instance from the dataset and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMkpiDcNvW0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e6af5ef2-ca85-474c-9dcd-4036b21fd6bf"
      },
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "picked_idx = random.randint(0, x_train.shape[0]-1)\n",
        "\n",
        "img_picked = x_train[picked_idx]\n",
        "label = y_train[picked_idx]\n",
        "\n",
        "plt.imshow(img_picked)\n",
        "print('Label: ', label)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDWW7n1Hwhe2"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Before we are ready to train our predict whether an image is a 1 or a 0, we need to do some preprocessing on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oikiBpenwhGD"
      },
      "source": [
        "# Neural networks play better with small numbers. Images tend to have pixel values between 0 and 255. \n",
        "# Rescale this to 0-1. Hint try dividing\n",
        "# Do this to x_train and x_test\n",
        "# Remember to store the output back into x_train and x_test\n",
        "x_train=(x_train/255)-0.5\n",
        "x_test=(x_test/255)-0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMqXkG11uvFx",
        "outputId": "3dd7e6f4-880b-4738-ff6f-a3e1eecd60b7"
      },
      "source": [
        "x_train.shape,x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 28, 28), (2115, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VsqKZSmyERP"
      },
      "source": [
        "# Since you will be using a regular Dense neural network. The network expects your data to be flattened from 2D to 1D\n",
        "# Rehsape the data from (N, 28, 28) to (N, 784) N represents number of images. \n",
        "# Each image is 28x28, we want to chage that to one flat row with 784\n",
        "x_train =x_train.reshape((-1,784))\n",
        "x_test =x_test.reshape((-1,784))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa2FYvIs5NgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78dc3e6-f681-44f0-945d-1ffe526ba9a5"
      },
      "source": [
        "x_train.shape,x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 784), (2115, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKUP2Sw4M_G"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9JEuHOPwRBG"
      },
      "source": [
        "Create a neural network model using tensorflow with at least 1 hidden layer. The output layer must have 1 unit. Experiment with different number of layers and number of units in each layer. This is where your creativitiy as a machine learning engineer comes in to play."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUKwJdclvshK"
      },
      "source": [
        "#create model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "#model = Sequential()\n",
        "#model.add(Dense(512, input_dim = 8, activation = 'relu')) \n",
        "#model.add(Dense(8, activation = 'relu'))\n",
        "#model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE3n1ppy0uVa"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpDTrhi40tW3"
      },
      "source": [
        "# Complie the model\n",
        "# Ensure you use the binary cross entropy loss function and sgd for your optmizer\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_dOXDNi0_NR"
      },
      "source": [
        "Now to train the model. Store the ouput of model.fit in a vairable called history as we are going to use this to plot the train accuracy and loss. Try different values for batch size and epochs. The aim is to get the highest test accuaracy possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hARFVH6S0-h7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a1805c-202c-4dd8-814c-d8013508f101"
      },
      "source": [
        "history = model.fit(x_train, y_train,epochs=150,batch_size = 5)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.1361 - accuracy: 0.9908\n",
            "Epoch 2/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0349 - accuracy: 0.9983\n",
            "Epoch 3/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0208 - accuracy: 0.9988\n",
            "Epoch 4/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0150 - accuracy: 0.9991\n",
            "Epoch 5/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0118 - accuracy: 0.9993\n",
            "Epoch 6/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0096 - accuracy: 0.9992\n",
            "Epoch 7/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0081 - accuracy: 0.9993\n",
            "Epoch 8/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0072 - accuracy: 0.9995\n",
            "Epoch 9/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0062 - accuracy: 0.9997\n",
            "Epoch 10/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0055 - accuracy: 0.9998\n",
            "Epoch 11/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0051 - accuracy: 0.9998\n",
            "Epoch 12/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0044 - accuracy: 0.9999\n",
            "Epoch 13/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0043 - accuracy: 0.9997\n",
            "Epoch 14/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0038 - accuracy: 0.9999\n",
            "Epoch 15/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0036 - accuracy: 0.9998\n",
            "Epoch 16/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "Epoch 17/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0031 - accuracy: 0.9999\n",
            "Epoch 18/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0029 - accuracy: 0.9999\n",
            "Epoch 19/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 20/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 21/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 22/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 23/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 24/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 25/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 26/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 27/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 28/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 29/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 30/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 32/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 33/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "2533/2533 [==============================] - 6s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 37/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 39/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 41/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 9.9013e-04 - accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 9.6331e-04 - accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 9.5074e-04 - accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 9.2453e-04 - accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 9.0485e-04 - accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 8.9158e-04 - accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 8.7060e-04 - accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 8.4524e-04 - accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 8.3756e-04 - accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 8.1954e-04 - accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 8.0445e-04 - accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 7.8654e-04 - accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 7.7503e-04 - accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 7.5815e-04 - accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 7.4593e-04 - accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 7.2943e-04 - accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "2533/2533 [==============================] - 6s 2ms/step - loss: 7.2026e-04 - accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 7.0664e-04 - accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.9793e-04 - accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.8614e-04 - accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.7363e-04 - accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.6390e-04 - accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.5145e-04 - accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.4428e-04 - accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.3288e-04 - accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.2367e-04 - accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.1526e-04 - accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 6.0596e-04 - accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.9794e-04 - accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.8723e-04 - accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.8105e-04 - accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.7248e-04 - accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.6479e-04 - accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.5760e-04 - accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.5014e-04 - accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.4165e-04 - accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.3592e-04 - accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.2861e-04 - accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.2207e-04 - accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.1575e-04 - accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.1047e-04 - accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 5.0386e-04 - accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.9708e-04 - accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.9184e-04 - accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.8556e-04 - accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.8031e-04 - accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.7421e-04 - accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.7016e-04 - accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.6466e-04 - accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.5903e-04 - accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.5404e-04 - accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.4900e-04 - accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.4481e-04 - accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.3992e-04 - accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.3496e-04 - accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.3107e-04 - accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.2529e-04 - accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.2226e-04 - accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.1829e-04 - accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.1392e-04 - accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.0924e-04 - accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.0536e-04 - accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 4.0147e-04 - accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.9800e-04 - accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.9381e-04 - accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.9041e-04 - accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.8691e-04 - accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.8303e-04 - accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.7954e-04 - accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.7636e-04 - accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.7268e-04 - accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.6961e-04 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.6626e-04 - accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.6318e-04 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.5989e-04 - accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.5678e-04 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.5360e-04 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.5097e-04 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.4742e-04 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.4493e-04 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.4217e-04 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.3892e-04 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.3680e-04 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.3400e-04 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.3059e-04 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.2879e-04 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.2597e-04 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.2358e-04 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.2108e-04 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.1858e-04 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.1619e-04 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.1388e-04 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.1135e-04 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.0916e-04 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.0657e-04 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.0444e-04 - accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.0186e-04 - accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 3.0025e-04 - accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.9795e-04 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.9577e-04 - accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.9365e-04 - accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.9162e-04 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.8972e-04 - accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.8782e-04 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "2533/2533 [==============================] - 5s 2ms/step - loss: 2.8568e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0yTm1s-4QgS"
      },
      "source": [
        "# Evalualtion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsSZglfz2G6y"
      },
      "source": [
        "Let's look at the plot of loss and accuracy. You should see accuracy going up and loss going down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hlS2dIZ2FU6"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj1-MpYE26Pd"
      },
      "source": [
        "Let us evaluate our model. Remember in machine learning what we are most interested in is the accuracy on the test dataset as this data represents data that the model has not seen during training so it should test the model's ability to generalize to new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhpjCErJ25YZ"
      },
      "source": [
        "#evalute the funtion\n",
        "output = model.evaluate(X_test, Y_test)\n",
        "print('Accuracy {:.2f}%'.format(out[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWwww_T_60Iu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "6a9289a5-b76f-44d1-afac-25828797ea01"
      },
      "source": [
        "picked_idx = random.randint(0, x_test.shape[0]-1)\n",
        "\n",
        "img_picked = x_test[picked_idx]\n",
        "label = y_test[picked_idx]\n",
        "print(img_picked.shape)\n",
        "pred_label = model.predict(img_picked.reshape(1, -1))\n",
        "\n",
        "plt.imshow(img_picked.reshape(28, 28))\n",
        "print('Label: ', label)\n",
        "print('Predicited Label', 1 if pred_label > 0.5 else 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784,)\n",
            "Label:  0\n",
            "Predicited Label 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-YnwLcXVg_2"
      },
      "source": [
        "# Logistic Regression Using SGD (BONUS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glKbICXKmJmG"
      },
      "source": [
        "$$\\sigma (x) = \\frac {1}{1 + e^{-x}}$$\n",
        "$$y_{pred} = \\sigma (W \\cdot X^{T} + b)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOzJsL2baTBV"
      },
      "source": [
        "\n",
        "# N - batch size\n",
        "# W - weight of shape (1, num_features)\n",
        "# b - bias of shape (1,)\n",
        "# X - matrix of shape (N, num_features)\n",
        "# returns output of  ypred of shape (N,) **make sure to reshape**\n",
        "# note you have to find the dot product of W and the transpose of X (look up how to do this using numpy)\n",
        "def model_predict(W, b, X):\n",
        "  b=0\n",
        "  y_pred= np.dot(W,X.T)+b \n",
        "\n",
        "  def activation_fn(y):\n",
        "    # return  sigmoid function applied to y\n",
        "    # note there is a function called np.exp\n",
        "    return 1/(1 + np.exp(y))\n",
        "  \n",
        "  "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvNdNV9wixbt"
      },
      "source": [
        "$$L = -\\frac{1}{N}\\sum y_{target}log(y_{pred}) + (1-y_{target})log(1-y_{pred})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQMuOnS3iCsr"
      },
      "source": [
        "\n",
        "# y_target - vector of targets of shape (N,)\n",
        "# y_pred - vector of predictions of shape (N, )\n",
        "# returns output of binary cross entropy loss function above\n",
        "# **note you can find the mean using np.mean**\n",
        "def loss_fn(y_target, y_pred):\n",
        "  N=len(X)\n",
        "  cost=[]\n",
        "  cost=-(1/N)*np.sum(y_target*np.log(y_pred)+(1-y_target)*np.log(1-y_pred))\n",
        "  return np.exp(cost)\n",
        "  "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8A7AY-XpBUP"
      },
      "source": [
        "$$\\frac{\\partial{L}}{\\partial{W}} = \\frac{1}{N}(y_{pred}-y_{target})\\cdot X$$\n",
        "$$\\frac{\\partial{L}}{\\partial{b}} = \\frac{1}{N}\\sum (y_{pred}-y_{target})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzj05MnAnvmD"
      },
      "source": [
        "\n",
        "# N - batch size \n",
        "# y_pred - vector of predicitions of shape (N,)\n",
        "# y_target - vector of targets of shape (N,)\n",
        "# X - matrix of shape (N, num_features)\n",
        "# returns dl_dw, dl_db - parital derivative of loss with respect to the weights, partial derivative of loss with respect \n",
        "# to bias note you have to find the dot product\n",
        "def gradient_calc(y_pred, y_target, X):\n",
        "  N=len(X)\n",
        "  dl_dw= 1/N*np.dot((y_pred-y_target).X)\n",
        "  dl_db= 1/N*np.sum(y_pred-y_target)\n",
        "  \n",
        "  return dl_dw, dl_db"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LkRo2VVRhSr"
      },
      "source": [
        "# Gradient descent\n",
        "$$ W = W - \\alpha \\frac{\\partial L}{\\partial W}$$\n",
        "$$ b = b - \\alpha \\frac{\\partial L}{\\partial b}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTQPDi5n4h1E"
      },
      "source": [
        "\n",
        "# W - weight of shape (1, num_features)\n",
        "# b - bias of shape(1,)\n",
        "# alpha - learning rate\n",
        "# dl_dw - partial derivative of loss with respect to weight of shape (1, num_features)\n",
        "# dl_db - partial derivative of loss with respect to bias (1,)\n",
        "# returns W, b - updated weight and bias\n",
        "def gradient_step(W, b, dl_dw, dl_db, alpha=0.01):\n",
        "  W_deriv=0\n",
        "  b_deriv=0\n",
        "  N=len(X)\n",
        "  for i in range(N):\n",
        "    #calculate patrial derivatives\n",
        "    #-2(dl_db-(Wdl_dw))\n",
        "    W_deriv += -2*dl_dw[i]* (dl_db[i]-(W*dl_dw[i]+ b))\n",
        "\n",
        "    #-2(dl_db-(Wdl_dw))\n",
        "    b_deriv += -2*(dl_db[i]-(W*dl_dw[i]+b))\n",
        "\n",
        "    W -= (W_deriv/ float(N))* alpha\n",
        "    b -= (b_deriv/ float(N))* alpha\n",
        "    return W, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhDHd4P78nei"
      },
      "source": [
        "Initialize weight and bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBGBap548EDj"
      },
      "source": [
        "W = np.random.randn(1, 784) \n",
        "b = np.zeros(1,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqCzOk52Vw3y"
      },
      "source": [
        "num_epochs = 20 #iterations through the entire dataset\n",
        "batch_size = 16\n",
        "alpha = 0.001 # learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D1qcUR-e5Ro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "8048dc8b-ab99-48ca-ef29-72558bc186e4"
      },
      "source": [
        "losses = []\n",
        "for i in range(num_epochs):\n",
        "  num_batches = len(x_train)//batch_size # split into mini batches\n",
        "  for j in range(num_batches):\n",
        "    X = x_train[j*batch_size:(j+1)*batch_size]\n",
        "    y_target = y_train[j*batch_size:(j+1)*batch_size]\n",
        "    y_pred = model_predict(W, b, X)\n",
        "    loss = loss_fn(y_target, y_pred)\n",
        "    dl_dw, dl_db = gradient_calc(y_pred, y_target, X)\n",
        "    W, b = gradient_step(W, b, dl_dw, dl_db, alpha)\n",
        "  losses.append(loss)\n",
        "  print('Epoch: ', i, ' Loss: ', loss)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'log'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-8a7fe0814942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdl_dw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_dw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-2fd04bd6ece3>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(y_target, y_pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type NoneType which has no callable log method"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyIPJjCJ86i0"
      },
      "source": [
        "Let us now plot the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQpWfppdWQrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e72b8645-471f-40fe-8483-e97eec3cb9f2"
      },
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa7bd10cf98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnl2qbaqaqw3"
      },
      "source": [
        "# Evaluation/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPXQTHm0aaHD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "810cfb81-1b5c-4876-f991-fe9133515aa2"
      },
      "source": [
        "picked_idx = random.randint(0, x_test.shape[0]-1)\n",
        "\n",
        "img_picked = x_test[picked_idx]\n",
        "label = y_test[picked_idx]\n",
        "print(img_picked.shape)\n",
        "pred_label = model_predict(W, b, img_picked.reshape(1, -1))\n",
        "plt.imshow(img_picked.reshape(28, 28))\n",
        "print('Label: ', label)\n",
        "print('Predicited Label', 1 if pred_label > 0.5 else 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784,)\n",
            "Label:  1\n",
            "Predicited Label 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zumoi8I29FGz"
      },
      "source": [
        "Let us see how well your model did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI4L0XEWa-Ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9aa364-cfce-45fe-bbf9-fd3c7df18b41"
      },
      "source": [
        "eval_pred = model_predict(W, b, x_test)\n",
        "eval_pred = (eval_pred > 0.5).astype(float) # anything with more than 50% probability is seen as a 1\n",
        "accuracy = np.mean((eval_pred == y_test).astype(float))\n",
        "print('Accuracy: {:.2f}%'.format(float(accuracy*100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.96%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}